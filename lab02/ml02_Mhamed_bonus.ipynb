{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Iris Dataset Analysis: Data - Inspect, Explore, Split \n",
    "**Author:** Mhamed  \n",
    "**Date:** 03, 21, 2025 \n",
    " \n",
    "**Objective:** The objective of this project is to perform a comprehensive analysis of the Iris dataset with the goal of building a predictive model for .............\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project analyzes the Titanic dataset to predict passenger survival based on various features. It involves importing and inspecting the data, performing exploratory data analysis, cleaning the data, engineering new features, and selecting relevant input features for modeling. The project also explores methods for splitting the data into training and testing sets to evaluate the performance of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "In the code cell below, import the necessary Python libraries for this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Python cell\n",
    "# All imports should be at the top of the notebook\n",
    "# This cell will be executed when the notebook is loaded\n",
    "\n",
    "# Import pandas for data manipulation and analysis (we might want to do more with it)\n",
    "import pandas as pd\n",
    "\n",
    "# Import pandas for data manipulation and analysis  (we might want to do more with it)\n",
    "import numpy as np\n",
    "\n",
    "# Import matplotlib for creating static visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import seaborn for statistical data visualization (built on matplotlib)\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the California housing dataset from sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Import train_test_split for splitting data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LinearRegression for building a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import performance metrics for model evaluation\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Import the necessary function\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2fca9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa\n",
       "5           5.4          3.9           1.7          0.4  setosa\n",
       "6           4.6          3.4           1.4          0.3  setosa\n",
       "7           5.0          3.4           1.5          0.2  setosa\n",
       "8           4.4          2.9           1.4          0.2  setosa\n",
       "9           4.9          3.1           1.5          0.1  setosa"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 1. Import and Inspect the Data\n",
    "# 1.1 Load the dataset and display the first 10 rows\n",
    "\n",
    "# Load Iris dataset\n",
    "df = sns.load_dataset('iris')\n",
    "\n",
    "# Show the first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3870f5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "First 10 Rows:\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "5           5.4          3.9           1.7          0.4  setosa\n",
      "6           4.6          3.4           1.4          0.3  setosa\n",
      "7           5.0          3.4           1.5          0.2  setosa\n",
      "8           4.4          2.9           1.4          0.2  setosa\n",
      "9           4.9          3.1           1.5          0.1  setosa\n",
      "Missing Values:\n",
      "sepal_length    0\n",
      "sepal_width     0\n",
      "petal_length    0\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n",
      "Summary Statistics:\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "Numeric Correlations:\n",
      "              sepal_length  sepal_width  petal_length  petal_width\n",
      "sepal_length      1.000000    -0.117570      0.871754     0.817941\n",
      "sepal_width      -0.117570     1.000000     -0.428440    -0.366126\n",
      "petal_length      0.871754    -0.428440      1.000000     0.962865\n",
      "petal_width       0.817941    -0.366126      0.962865     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Section 1. Import and Inspect the Data\n",
    "# 1.1 Load the dataset and display the first 10 rows\n",
    "\n",
    "# Load Iris dataset\n",
    "\n",
    "df = sns.load_dataset('iris')\n",
    "# Load dataset\n",
    "\n",
    "# If command is not the last statement in a Python cell, you'll have to wrap in the print() function to display.\n",
    "print('Info:')\n",
    "print(df.info())\n",
    "print('First 10 Rows:')\n",
    "print(df.head(10))\n",
    "print('Missing Values:')\n",
    "print(df.isnull().sum())\n",
    "print('Summary Statistics:')\n",
    "print(df.describe())\n",
    "print('Numeric Correlations:')\n",
    "print(df.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Markdown cell.\n",
    "\n",
    "### 1.2 Check for missing values and display summary statistics\n",
    "\n",
    "In the cell below:\n",
    "1. Use `info()` to check data types and missing values.\n",
    "2. Use `describe()` to see summary statistics.\n",
    "3. Use `isnull().sum()` to identify missing values in each column.\n",
    "\n",
    "Example code:\n",
    "\n",
    "data_frame.info()\n",
    "\n",
    "data_frame.describe()\n",
    "\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "Summary Statistics:\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python\n",
    "# Check data types and missing values\n",
    "\n",
    "print(\"Data Info:\")\n",
    "df.info()\n",
    "\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e077e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correlation Matrix (numeric features only):\n",
      "              sepal_length  sepal_width  petal_length  petal_width\n",
      "sepal_length      1.000000    -0.117570      0.871754     0.817941\n",
      "sepal_width      -0.117570     1.000000     -0.428440    -0.366126\n",
      "petal_length      0.871754    -0.428440      1.000000     0.962865\n",
      "petal_width       0.817941    -0.366126      0.962865     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for correlations useing the corr() method\n",
    "\n",
    "print(\"\\nCorrelation Matrix (numeric features only):\")\n",
    "print(df.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c001a63",
   "metadata": {},
   "source": [
    "## Reflection 1\n",
    "1) How many data instances are there? 891 rows\n",
    "2) How many features are there? 15 features (columns)\n",
    "3) What are the names? survived, pclass sex, age, sibsp, parch, fare, embarked, class, who, adult_male, deck, embark_town, alive, alone\n",
    "4) Are there any missing values? Yes age (177), embarked (2), embark_town (2), deck (688).\n",
    "5) Are there any non-numeric features? Yes sex, embarked, class, who, embark_town, alive\n",
    "6) Are the data instances sorted on any of the attributes? No\n",
    "7) What are the units of age? Years\n",
    "8) What are the minimum, median and max age? Min is 0.42, median is 28, and max is 80\n",
    "9) What two different features have the highest correlation? Parch and Sibsp at 0.414838\n",
    "10) Are there any categorical features that might be useful for prediction? Sex might be useful feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation\n",
    "Now we need to explore our dataset with charts \n",
    "\n",
    "2.1 Explore Data Patterns and Distributions\n",
    "Create a scatter matrix.\n",
    "Since Titanic contains both numeric and categorical variables, we'll use only numeric values here.\n",
    "\n",
    "Important:  Use only numeric attributes for the scatter matrix. If you want to explore categorical data, use count plots and bar plots instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric features\n",
    "attributes = ['age', 'fare', 'pclass']\n",
    "# Create scatter matrix\n",
    "scatter_matrix(df[attributes], figsize=(10, 10), color='darkgreen')\n",
    "\n",
    "# Title\n",
    "plt.suptitle(\"Scatter Matrix: Age, Fare, Pclass\")\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f666625",
   "metadata": {},
   "source": [
    "    2.1.1 Create a scatter plot of age vs fare, colored by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for males (0)\n",
    "male_data = df[df['sex'] == 'male']\n",
    "plt.scatter(\n",
    "    male_data['age'], \n",
    "    male_data['fare'], \n",
    "    c='blue', \n",
    "    label='Male', \n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Plot for females (1)\n",
    "female_data = df[df['sex'] == 'female']\n",
    "plt.scatter(\n",
    "    female_data['age'], \n",
    "    female_data['fare'], \n",
    "    c='red', \n",
    "    label='Female', \n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Age vs Fare by Gender')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Gender\")\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff8a41",
   "metadata": {},
   "source": [
    "    2.1.2 Create a histogram of age \"Age Distribution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Age\n",
    "# Plot histogram with KDE (Kernel Density Estimate)\n",
    "sns.histplot(df['age'], kde=True, color='red')\n",
    "\n",
    "# Add title and display\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e57d64",
   "metadata": {},
   "source": [
    "2.1.3 Create a count plot for class and survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Plot - Class Distribution by Survival\n",
    "# Count plot: Passenger class with survival hue\n",
    "sns.countplot(x='class', hue='survived', data=df)\n",
    "\n",
    "# Add title and display\n",
    "plt.title('Class Distribution by Survival')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Survived', labels=['Not Survived', 'Survived'])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280fa27",
   "metadata": {},
   "source": [
    "Reflection 2.1:\n",
    "\n",
    "* What patterns or anomalies do you notice?\n",
    "    - First-class passengers pay higher fares, while third-class passengers pay lower fares.\n",
    "    - Age Distribution: The distribution skews toward younger passengers, possibly indicating more children or young adults.\n",
    "    - Age has 177 missing values and deck has 688 missing values.\n",
    "    - Third-class passengers dominate the dataset, with lower survival rates\n",
    "\n",
    "* Do any features stand out as potential predictors?\n",
    "    - Class: Strongly correlated with fare and survival, with survival rates varying across classes.\n",
    "    - Sex: Women had a higher survival rate, making it an important predictor.\n",
    "\n",
    "* Are there any visible class imbalances?\n",
    "    - There is a clear imbalance between the survival rates in different classes, with third-class passengers having a significantly lower survival rate compared to those in first or second class.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7c8b5",
   "metadata": {},
   "source": [
    "2.2 Handle Missing Values and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec88eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'age' with the median age\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "\n",
    "# Fill missing values in 'embark_town' with the most frequent value (mode)\n",
    "df['embark_town'] = df['embark_town'].fillna(df['embark_town'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52575dde",
   "metadata": {},
   "source": [
    "2.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49140dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a new feature: Family size\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "\n",
    "# 2. Convert categorical variables to numeric\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# 3. Create a binary feature for 'alone':\n",
    "df['alone'] = df['alone'].astype(int)\n",
    "\n",
    "# Print outcome\n",
    "print(df[['sex', 'embarked', 'family_size', 'alone']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecda3d5",
   "metadata": {},
   "source": [
    "Reflection 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7a0ca",
   "metadata": {},
   "source": [
    "- Why might family size be a useful feature for predicting survival? Family size could influence Titanic survival chances, as people traveling with family might have had a better chance of survival because family groups were more likely to stay together.\n",
    "\n",
    "- Why convert categorical data to numeric? Converting categorical data to numeric format is a common step in preparing data for machine learning algorithms. The sex and embarked columns are transformed into numerical values so they can be directly used in predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63039b27",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "\n",
    "### 3.1 Feature Selection and Target Variable\n",
    "\n",
    "Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "Select a target variable (as applicable)\n",
    "\n",
    "For classification, we’ll use survived as the target variable.\n",
    "\n",
    "Input features: age, fare, pclass, sex, family_size\n",
    "Target: survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b956369c",
   "metadata": {},
   "source": [
    "### 3.2 Define X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbef2e4",
   "metadata": {},
   "source": [
    "- Assign input features to X\n",
    "- Assign target variable to y (as applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'fare', 'pclass', 'sex', 'family_size']]\n",
    "y = df['survived']\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f22e11",
   "metadata": {},
   "source": [
    "### Reflection 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb500c",
   "metadata": {},
   "source": [
    "- Why are these features selected? Theses selected features are chosen for their relevance in predicting Titanic survival\n",
    "- Are there any features that are likely to be highly predictive of survival? Yes, certain features are more predictive of survival, such as sex, pclass, and family_size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3a4de",
   "metadata": {},
   "source": [
    "## Section 4. Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Section 4. Train a Linear Regression Model\n",
    "# Section 4.1: Basic Train/Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Section 4.2: Stratified Train/Test Split\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    X_train_strat = X.iloc[train_indices]\n",
    "    X_test_strat = X.iloc[test_indices]\n",
    "    y_train_strat = y.iloc[train_indices]\n",
    "    y_test_strat = y.iloc[test_indices]\n",
    "\n",
    "# Section 4.3: Compare Class Distributions\n",
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"\\nBasic Train Set Class Distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Basic Test Set Class Distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "print(\"\\nStratified Train Set Class Distribution:\\n\", y_train_strat.value_counts(normalize=True))\n",
    "print(\"Stratified Test Set Class Distribution:\\n\", y_test_strat.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338a131",
   "metadata": {},
   "source": [
    "## Reflection 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efd644",
   "metadata": {},
   "source": [
    "1. Why might stratification improve model performance? Stratification improves model performance by ensuring that the class distributions in both the training and test sets are more representative of the overall dataset.\n",
    "\n",
    "2. How close are the training and test distributions to the original dataset? Based on the outputs, both split methods produce train/test distributions are close to the original dataset. However, stratification maintains a more accurate balance, especially in the test set, where the distribution more closely mirrors the original class proportions.\n",
    "    \n",
    "3. Which split method produced better class balance? The stratified split method maintained a class distribution closer to the original dataset, offering a more accurate representation in both the training and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
